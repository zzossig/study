## Concurrency vs Parallelism

동시성(concurrency)과 Parallelism(병렬성)은 비슷하면서도 다른 개념이라 정리해둔다.

### 동시성(Concurrency)

`동시성`이란 cpu 하나가 여러개의 작업 프로세스를 번갈아 가며 실행하는 것을 뜻한다. 예를들어 작업 프로세스가 동영상 재생이라고 치자. cpu코어가 1개인 컴퓨터에서 동영상을 동시에 2~3개정도 재생했을 때, 모니터로 보이는 동영상은 끊김이 없어 보이지만 사실, cpu가 2~3개의 동영상을 매우 짧은 시간동안 번갈아가면서 처리하기 때문에 우리 눈에는 영상이 끊김없이 재생되는 것 처럼 보이는 것이다.
만약, cpu 코어가 1개인 컴퓨터에서 동영상을 100개 이상 실행시키면 어떻게 될까? cpu의 성능에 따라 다르겠지만 아마 10개 이상의 동영상을 실행시키는 순간부터 동영상들이 끊기는 것을 체감할 수 있을 것이다. cpu는 한번에 하나의 동영상만을 처리하기 때문에 다른 동영상들은 처리되지 않는 순간에는 멈추기 때문이다.
그럼 cpu 코어가 1개인 컴퓨터에서 동영상을 1000개 이상(정말 많이) 실행시키면 어떻게 될까? 아마 이때부터는 쓰레드간 switching(혹은 context switching) 시간이 동영상을 처리하는 시간을 훨씬 초과하게 되어 영상이 아주 멈춘 것 처럼 보일 것이다.(물론 이 이야기는 내 머릿속으로 가상으로 그린 것이며 실제로 1000개의 동영상을 실행하기도 전에 cpu에 과부하가 걸릴 것 같긴 하다.). 쓰레드간 스위칭은 cpu가 하나의 영상을 처리하고 다음 영상을 처리하려고 할 때 쓰는 자원 소모를 말한다.

### 병렬성(Parallelism)

`병렬성`은 실제로 작업 프로세스가 동시에 실행되는 것을 말한다. 동시에 여러 프로세스가 실행되려면 멀티코어 cpu는 필수다. 만약 16코어 cpu가 있다면 16개의 프로세스를 동시에(눈에 보이는 동시가 아닌 진짜 동시에) 실행 시킬 수 있으며, context switcing이 일어나지 않기 때문에 더 빠른 일처리가 가능 하다.

## Moore's Law, Web Scale, and the Mess We're In

무어의 법칙은 다들 알다시피 집접회로의 성능이 24개월마다 2배로 증가한다는 법칙이다. 이 법칙은 2012년 까지 유효했다. 물론 복리의 마법에 따라, 매번 2배로 증가한다는 말은 말이 안되는 소리이긴 하지만, 당시에는 기술적으로 그정도까지 발전할 수 있었던 것 같다. 성능이 2배로 증가한다는 말은, 단일 코어의 처리 속도가 2배가 된다는 말이다. 그 말인즉, 1개의 cpu로 더 많은 프로세스를 더 빠르게 처리한다는 말이다.
이게 한계에 부딪히자, cpu의 코어를 더 늘려서 작업을 병렬로 처리하는 방향으로 cpu가 발전하게 된다.
cpu의 코어가 늘어감에 따라 병렬로 연산을 처리할 수 있는 기술도 발전하고 있고 있다.

특히 클라우드 컴퓨팅이 가능해 지면서, 컴퓨터 자원의 scaling horizontally가 점점 쉬워지고 있다. 상대적으로 싼 값에 컴퓨팅 자원을 확보할 수 있게 되면서, 아이디어와 기술만 있다면 더 큰 규모의 서비스 도 만들 수 있게 되었다. 특히 웹은 기본적으로 트래픽을 동시에 처리해야 하기 때문에 병렬성이 원래부터 중요한 분야다.

그러니까 이제부터 컴퓨팅은 병렬성이 중요해 졌고 더 중요해 질 것이다. 병렬성이 중요해지면서 새로운 challenges를 만들어 냈는데, 첫째, 컴퓨팅 자원을 어떻게 provisioning 할 것인가. 둘째, 인스턴스 간 어떻게 커뮤니케이션 할 것인가. 셋째, 결과들을 모으고 저장하는 일. 넷째, 이게 가장 어려운 일인데, 코드 차원에서 병렬성(혹은 동시성)을 어떻게 모델링 할 것인가.